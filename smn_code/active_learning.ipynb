{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130de07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from model_training_and_evaluation import *\n",
    "from model_testing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c6649",
   "metadata": {},
   "source": [
    "# Active Learning\n",
    "\n",
    "This notebook will be used to perform active learning to create labels for the dataset. If you ever want to reuse this code you might want to do some of the following changes:\n",
    "- Update the corrected file after each label you manually set, so that if the code fails along the way what you have labeled is not lost. Then the code will also be updated so that when you start running the code again you can just continue where you stopped. \n",
    "- Specifically updating/saving the yet uncorrected examples at least after every manual labeling, or more frequently as the point above.\n",
    "\n",
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_most_uncertain_labels(full_df: pd.DataFrame, num_to_correct: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to correct the most uncertain labels in a dataframe. \n",
    "    Args:\n",
    "        full_df: a dataframe on the format |Text|Label|Score|\n",
    "        num_to_correct: the number of labels that should be corrected\n",
    "    Returns:\n",
    "        The corrected dataframe and a dataframe consisting of the entries that were not corrected, so\n",
    "        that future prediction is not done on the corrected examples\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort and find the most uncertain email labels\n",
    "    full_df_sorted = full_df.sort_values('score')\n",
    "    n_most_uncertain = full_df_sorted.head(num_to_correct)\n",
    "    most_certain = full_df_sorted.tail(full_df.shape[0] - num_to_correct)\n",
    "\n",
    "    # Fix the most uncertain labels\n",
    "    for index, row in n_most_uncertain.iterrows():\n",
    "        print(f'label er: {row[\"label\"]} og text er: \\n{row[\"text\"]}')\n",
    "        correct_label = input('correct label: ')\n",
    "        correct_label = 0 if correct_label == '0' else 1\n",
    "        n_most_uncertain.loc[index, 'label'] = correct_label\n",
    "        print('\\n')\n",
    "\n",
    "    # Add the corrected labels to the corrected.csv file\n",
    "    if os.path.isfile('./corrected.csv'):\n",
    "        # Add new rows to csv if there already exist a csv with this name\n",
    "        corrected = pd.read_csv('./corrected.csv')\n",
    "        corrected =  pd.concat([corrected, n_most_uncertain], ignore_index=True)\n",
    "        corrected.to_csv('./corrected.csv', index=False)\n",
    "    else:\n",
    "        # If this is the first time correcting labels, no file exist yet with this name\n",
    "        corrected = n_most_uncertain\n",
    "        corrected.to_csv('./corrected.csv', index=False)\n",
    "    \n",
    "    return corrected, most_certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c410d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f0d89",
   "metadata": {},
   "source": [
    "## Prediction 1 with 0 examples\n",
    "\n",
    "Transfer learning will be used to make initial predictions on the dataset. I will use an NB-BERT model trained on the NoReC dataset for this purpose. This model can be loaded from huggingface, however the VM does not allow for downloading models trough the code, so it must first be downloaded manually and saved to a folder, then loaded through the code. \n",
    "\n",
    "Note: the numbers in e.g. results_0 or corrected_50 says how many examples have been used for training so far, meaning that it starts at 0 and increases after each training by the number of additional examples used for training that round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4c5d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do predictions using the model and save them as pred_0.csv as well in case the kernel closes\n",
    "preprocessed_emails = pd.read_csv('preprocessed_emails_10k_2023_rensket')\n",
    "results_0 = predict_from_fine_tuned_model('./models/nb-bert_LR5e-05_WR0.1_OPTIMadamw_hf_WD0', list(preprocessed_emails['email']))\n",
    "results_0.to_csv('./temp_pred_during_al/pred_0.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_0 as well)\n",
    "# Correct those examples and save as the manually labeled dataset\n",
    "corrected_0, not_corrected_0 = correct_most_uncertain_labels(results_0, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccadead0",
   "metadata": {},
   "source": [
    "## Prediction 2 with new dataset containing 50 examples\n",
    "\n",
    "Now that a small dataset has been manually labeled, the model can be further trained on that data and predictions can be tried again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0d59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_0_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/nb-bert_LR5e-05_WR0.1_OPTIMadamw_hf_WD0')\n",
    "init_corrected_0_encoding = corrected_0_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_0_encoded = init_corrected_0_encoding['train']\n",
    "\n",
    "# train model. nb-bert_LR5e-05_WR0.1_OPTIMadamw_hf_WD0 is the model trained on this VM\n",
    "# NOTE: this model has been overwritten after the AL process was performed by a model actually trained on\n",
    "# the final dataset from this process, meaning that this model is no longer the one trained on the \n",
    "# NoReC dataset. \n",
    "model_path_50 = create_and_train_model('./models/nb-bert_LR5e-05_WR0.1_OPTIMadamw_hf_WD0',\n",
    "                      'nb-bert',\n",
    "                      corrected_0_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=50)\n",
    "\n",
    "# Load model trained on 50 examples to do predictions using the model and save them as pred_50\n",
    "results_50 = predict_from_fine_tuned_model(model_path_50, list(not_corrected_0['text']))\n",
    "results_50.to_csv('./temp_pred_during_al/pred_50.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_50 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_50, not_corrected_50 = correct_most_uncertain_labels(results_50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed431743",
   "metadata": {},
   "source": [
    "## Prediction 3 with 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2531e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_50_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex50')\n",
    "init_corrected_50_encoding = corrected_50_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_50_encoded = init_corrected_50_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_100 = create_and_train_model('./models/models_al/nb-bert_ex50',\n",
    "                      'nb-bert',\n",
    "                      corrected_50_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=100)\n",
    "\n",
    "# Load model trained on 100 examples to do predictions using the model and save them as pred_100\n",
    "results_100 = predict_from_fine_tuned_model(model_path_100, list(not_corrected_50['text']))\n",
    "results_100.to_csv('./temp_pred_during_al/pred_100.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_100 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_100, not_corrected_100 = correct_most_uncertain_labels(results_100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7452f46",
   "metadata": {},
   "source": [
    "## Prediction 4 with 150 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6acbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_100_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex100')\n",
    "init_corrected_100_encoding = corrected_100_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_100_encoded = init_corrected_100_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_150 = create_and_train_model('./models/models_al/nb-bert_ex100',\n",
    "                      'nb-bert',\n",
    "                      corrected_100_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=150)\n",
    "\n",
    "# Load model trained on 150 examples to do predictions using the model and save them as pred_150\n",
    "results_150 = predict_from_fine_tuned_model(model_path_150, list(not_corrected_100['text']))\n",
    "results_150.to_csv('./temp_pred_during_al/pred_150.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_150 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_150, not_corrected_150 = correct_most_uncertain_labels(results_150, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c8166",
   "metadata": {},
   "source": [
    "## Prediction 5 with 200 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd777b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_150_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex150')\n",
    "init_corrected_150_encoding = corrected_150_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_150_encoded = init_corrected_150_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_200 = create_and_train_model('./models/models_al/nb-bert_ex150',\n",
    "                      'nb-bert',\n",
    "                      corrected_150_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=200)\n",
    "\n",
    "# Load model trained on 150 examples to do predictions using the model and save them as pred_200\n",
    "results_200 = predict_from_fine_tuned_model(model_path_200, list(not_corrected_150['text']))\n",
    "results_200.to_csv('./temp_pred_during_al/pred_200.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_200 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_200, not_corrected_200 = correct_most_uncertain_labels(results_200, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7411ce0",
   "metadata": {},
   "source": [
    "## Prediction 6 with 250 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38f513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_200_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex200')\n",
    "init_corrected_200_encoding = corrected_200_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_200_encoded = init_corrected_200_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_250 = create_and_train_model('./models/models_al/nb-bert_ex200',\n",
    "                      'nb-bert',\n",
    "                      corrected_200_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=250)\n",
    "\n",
    "# Load model trained on 200 examples to do predictions using the model and save them as pred_250\n",
    "results_250 = predict_from_fine_tuned_model(model_path_250, list(not_corrected_200['text']))\n",
    "results_250.to_csv('./temp_pred_during_al/pred_250.csv', index=False)\n",
    "\n",
    "# Extract 50 most uncertain examples (remove them from pred_250 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_250, not_corrected_250 = correct_most_uncertain_labels(results_250, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e74e75",
   "metadata": {},
   "source": [
    "## Prediction 7 with 300 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18be66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_250_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex250')\n",
    "init_corrected_250_encoding = corrected_250_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_250_encoded = init_corrected_250_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_300 = create_and_train_model('./models/models_al/nb-bert_ex250',\n",
    "                      'nb-bert',\n",
    "                      corrected_250_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=300)\n",
    "\n",
    "# Load model trained on 300 examples to do predictions using the model and save them as pred_300\n",
    "results_300 = predict_from_fine_tuned_model(model_path_300, list(not_corrected_250['text']))\n",
    "results_300.to_csv('./temp_pred_during_al/pred_300.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb379b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract 100 most uncertain examples (remove them from pred_250 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_300, not_corrected_300 = correct_most_uncertain_labels(results_300, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea7f84",
   "metadata": {},
   "source": [
    "## Prediction 8 with 400 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094b67d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_300_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex300')\n",
    "init_corrected_300_encoding = corrected_300_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_300_encoded = init_corrected_300_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_400 = create_and_train_model('./models/models_al/nb-bert_ex300',\n",
    "                      'nb-bert',\n",
    "                      corrected_300_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=400)\n",
    "\n",
    "# Load model trained on 400 examples to do predictions using the model and save them as pred_400\n",
    "results_400 = predict_from_fine_tuned_model(model_path_400, list(not_corrected_300['text']))\n",
    "results_400.to_csv('./temp_pred_during_al/pred_400.csv', index=False)\n",
    "\n",
    "# Extract 100 most uncertain examples (remove them from pred_400 as well)\n",
    "# Correct those examples and add to the manually labeled dataset\n",
    "corrected_400, not_corrected_400 = correct_most_uncertain_labels(results_400, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b5d89",
   "metadata": {},
   "source": [
    "## Prediction 9 with 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af9f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize current training dataset\n",
    "corrected_400_dataset = load_dataset('csv', data_files='./corrected.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex400')\n",
    "init_corrected_400_encoding = corrected_400_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "corrected_400_encoded = init_corrected_400_encoding['train']\n",
    "\n",
    "# train model \n",
    "model_path_500 = create_and_train_model('./models/models_al/nb-bert_ex400',\n",
    "                      'nb-bert',\n",
    "                      corrected_400_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=500)\n",
    "\n",
    "# Load model trained on 500 examples to do predictions using the model and save them as pred_500\n",
    "results_500 = predict_from_fine_tuned_model(model_path_500, list(not_corrected_400['text']))\n",
    "results_500.to_csv('./temp_pred_during_al/pred_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19131ef",
   "metadata": {},
   "source": [
    "## Sort data and save final dataset\n",
    "\n",
    "After looking at the dataset created by training on 400 and 500 examples, I thought the one trained on 400 looked a bit better, so I decided to go with that. Most likely, the dataset trained on 500 examples overfitted to the data, so it was not able to see that negative emails about other things than insurance/interests could actually be negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354790ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_400.sort_values('score', inplace=True)\n",
    "results_400.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd636ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_400.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_400.to_csv('./temp_pred_during_al/pred_400_sorted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3baf2",
   "metadata": {},
   "source": [
    "## Create dataset to be corrected manually by employees at SMN\n",
    "\n",
    "The people at SMN will only be correcting the 100 most and 100 least certain examples, so these will be extracted. Since there seem to be a pattern in which examples the model is most certain of, the examples are shuffled. Also, I noticed that among the most certain examples, pretty much everyone were marked as positive. Therefore, the dataset to correct is balanced, so that the 50 most certain and 50 least certain positive examples, and the 50 most certain and 50 least certain negative examples are corrected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_examples = results_400[results_400['label'] == 'LABEL_1']\n",
    "neg_examples = results_400[results_400['label'] == 'LABEL_0']\n",
    "pos_50_least_certain = pos_examples.head(50)\n",
    "pos_50_most_certain = pos_examples.tail(50)\n",
    "neg_50_least_certain = neg_examples.head(50)\n",
    "neg_50_most_certain = neg_examples.tail(50)\n",
    "df_for_correction = pd.concat([pos_50_least_certain, pos_50_most_certain, neg_50_least_certain, neg_50_most_certain])\n",
    "df_for_correction = df_for_correction.sample(frac=1)\n",
    "df_for_correction.drop(['score'], axis=1, inplace=True)\n",
    "df_for_correction.to_csv('./temp_pred_during_al/predictions_to_be_corrected.csv', index=False)\n",
    "df_for_correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611118d1",
   "metadata": {},
   "source": [
    "## Use the final manually labeled dataset for training as well\n",
    "\n",
    "The dataset that was manually labeled by employees will now be added to the dataset of manually labeled examples and one more round of training and predictions will be done. \n",
    "\n",
    "#### Add the dataset labeled by SMN to previous corrected, and fix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset labeled by SMN\n",
    "neg_dataset_corrected_by_smn = pd.read_csv('./100_negative_examples_labeled_by_smn_employees.csv', usecols=[0,1,2], sep=';')\n",
    "pos_dataset_corrected_by_smn = pd.read_csv('./100_positive_examples_labeled_by_smn_employees.csv', usecols=[0,1,2], sep=';')\n",
    "\n",
    "# Change label if it was wrong\n",
    "neg_dataset_corrected_by_smn.loc[neg_dataset_corrected_by_smn['Vurdering'] == 'Feil', 'Kategori'] = 'LABEL_1'\n",
    "pos_dataset_corrected_by_smn.loc[pos_dataset_corrected_by_smn['Vurdering'] == 'Feil', 'Kategori'] = 'LABEL_0'\n",
    "\n",
    "# Rename columns\n",
    "neg_dataset_corrected_by_smn.rename(columns={'Tekst':'text', 'Kategori':'label'}, inplace=True)\n",
    "pos_dataset_corrected_by_smn.rename(columns={'Tekst':'text', 'Kategori':'label'}, inplace=True)\n",
    "\n",
    "# Remove the 'Vurdering' column\n",
    "neg_dataset_corrected_by_smn.drop('Vurdering', inplace=True, axis=1)\n",
    "pos_dataset_corrected_by_smn.drop('Vurdering', inplace=True, axis=1)\n",
    "\n",
    "# Add to previously labeled dataset and save the final dataset\n",
    "# NB: If you run this again it will technically be wrong since the corrected.csv file has been updated after this\n",
    "# line of code was ran (see further down).\n",
    "corrected = pd.read_csv('./corrected.csv')\n",
    "corrected_final =  pd.concat([corrected, neg_dataset_corrected_by_smn, pos_dataset_corrected_by_smn], ignore_index=True)\n",
    "\n",
    "# Turn LABEL_1 to 1 and LABEL_0 to 0 to match the format of previous corrected emails\n",
    "corrected_final.loc[corrected_final['label'] == 'LABEL_0', 'label'] = 0\n",
    "corrected_final.loc[corrected_final['label'] == 'LABEL_1', 'label'] = 1\n",
    "\n",
    "corrected_final.to_csv('./corrected.csv', index=False)\n",
    "\n",
    "corrected_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac94672",
   "metadata": {},
   "source": [
    "#### Create dataset for predicitons later\n",
    "\n",
    "Unfortunately, the final dataset where all examples in corrected and the ones corrected by Sparebank 1 SMN are present is not saved, so I will have to start with pred_400 and from there remove all examples that also happen to be in corrected, as predictions should not be done on examples seen during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9b461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_400 = pd.read_csv('temp_pred_during_al/pred_400.csv')\n",
    "\n",
    "rows_to_delete = []\n",
    "for index, row in pred_400.iterrows():\n",
    "    if row['text'] in list(corrected_final['text']):\n",
    "        rows_to_delete.append(index)\n",
    "\n",
    "df_for_final_prediction = pred_400.drop(rows_to_delete)\n",
    "df_for_final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f816a5",
   "metadata": {},
   "source": [
    "#### Final training and prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067a22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turn dataframe to huggingface dataset\n",
    "corrected_final_dataset = Dataset.from_pandas(corrected_final)\n",
    "print(corrected_final_dataset)\n",
    "\n",
    "\n",
    "# tokenize current training dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/models_al/nb-bert_ex400')\n",
    "corrected_final_encoded = corrected_final_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# train model. nb-bert_ex400 is the previously trained model that created the labels for the dataset that was corrected by \n",
    "# SMN employees\n",
    "model_path_600 = create_and_train_model('./models/models_al/nb-bert_ex400',\n",
    "                      'nb-bert',\n",
    "                      corrected_final_encoded,\n",
    "                      al=True,\n",
    "                      num_al_examples=600)\n",
    "\n",
    "# Load model trained on 600 examples to do predictions on uncorrected examples using the model and save them as pred_600\n",
    "results_600 = predict_from_fine_tuned_model(model_path_600, list(df_for_final_prediction['text']))\n",
    "results_600.to_csv('./temp_pred_during_al/pred_600.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2eabb",
   "metadata": {},
   "source": [
    "#### Examine the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_600 = pd.read_csv('./temp_pred_during_al/pred_600.csv')\n",
    "results_600.value_counts('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d66a703",
   "metadata": {},
   "source": [
    "Something has obviously gone wrong here (probably overfitting). There are definetely too few negative emails, and this dataset has so few negative emails that it will be completely useless to train a BERT model. Seems like the best solution is to use pred_400, as that is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
